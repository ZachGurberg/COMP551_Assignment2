{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Verify(expression: bool, message: str):\n",
    "    if not expression:\n",
    "        raise Exception(message)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task 1.1: IMDB Data loading</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class IMDBSample:\n",
    "    def __init__(self, rowIndex, numberOfFeatures=89527):\n",
    "        self.rowIndex = rowIndex\n",
    "        self.features = np.zeros(numberOfFeatures)\n",
    "        self.label = -1\n",
    "\n",
    "class IMDBDataLoader:\n",
    "    def __init__(self, vocabFilepath, featFilepath):\n",
    "        self.samples = []\n",
    "        self.words = []\n",
    "        self.vocabFilepath = vocabFilepath\n",
    "        self.featFilepath = featFilepath\n",
    "        self.ParseIntoVectors()\n",
    "    \n",
    "    def ParseIntoVectors(self):\n",
    "        with open(self.featFilepath, 'r', encoding='utf-8') as file:\n",
    "            for line_number, line in enumerate(file, start=0):\n",
    "                currentSample = IMDBSample(line_number)\n",
    "                parts = line.split()\n",
    "                Verify(int(parts[0])>6 or int(parts[0]) < 6, \"Error: Rating value unexpected in IMDB dataloader.\")\n",
    "                currentSample.label = int(int(parts[0]))\n",
    "                for part in parts[1:]:\n",
    "                    wordIndex, frequency = map(int, part.split(':'))\n",
    "                    Verify(wordIndex<currentSample.features.size, \"Word index larger than number of features in IMDB dataloader\")\n",
    "                    Verify(frequency>=0, \"Word Frequency is smaller than expected in IMDB dataloader.\")\n",
    "                    currentSample.features[wordIndex] = frequency\n",
    "                self.samples.append(currentSample)\n",
    "\n",
    "        with open(self.vocabFilepath, 'r', encoding='utf-8') as file:\n",
    "            for line_number, line in enumerate(file, start = 0):\n",
    "                self.words.append(line)\n",
    "                \n",
    "    \n",
    "    def GetData(self):\n",
    "        numberOfSamples = len(self.samples)\n",
    "        numberOfFeatures = self.samples[0].features.size if self.samples else 0\n",
    "\n",
    "        X = np.zeros((numberOfSamples, numberOfFeatures))\n",
    "        y = np.zeros(numberOfSamples)\n",
    "\n",
    "        for i, sample in enumerate(self.samples):\n",
    "            X[i,:] = sample.features\n",
    "            y[i] = sample.label\n",
    "        return y, X\n",
    "    \n",
    "    def GetWords(self):\n",
    "        return self.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data loading</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloading complete\n"
     ]
    }
   ],
   "source": [
    "vocabFilepath = '../aclImdb/imdb.vocab'\n",
    "trainfeatFilepath = '../aclImdb/train/labeledBow.feat'\n",
    "testfeatFilepath = '../aclImdb/test/labeledBow.feat'\n",
    "dataloaderTrain = IMDBDataLoader(vocabFilepath, trainfeatFilepath)\n",
    "dataloaderTest = IMDBDataLoader(vocabFilepath, testfeatFilepath)\n",
    "print(\"Dataloading complete\")\n",
    "y_train, X_train = dataloaderTrain.GetData()\n",
    "y_test, X_test = dataloaderTest.GetData()\n",
    "\n",
    "words = dataloaderTrain.GetWords()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data filtering</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "onePercentThreshold = int(y_train.size*0.01)\n",
    "fiftyPercentThreshold = int(y_train.size*0.5)\n",
    "featureFrequencies = np.sum(X_train > 0, axis=0)\n",
    "\n",
    "featuresToKeep = (featureFrequencies > onePercentThreshold) & (featureFrequencies < fiftyPercentThreshold)\n",
    "featureFrequenciesFiltered = featureFrequencies[featuresToKeep]\n",
    "XFiltered_train = X_train[:, featuresToKeep]\n",
    "XFiltered_test = X_test[:, featuresToKeep]\n",
    "wordsFiltered = [word for word, keep in zip(words, featuresToKeep) if keep]\n",
    "\n",
    "weights = np.linalg.inv(XFiltered_train.T @ XFiltered_train) @ XFiltered_train.T @ y_train #OLS SSE Solution\n",
    "D_Selected = 1000\n",
    "feature_importances = np.abs(np.copy(weights))\n",
    "top_features_indices = np.argsort(feature_importances)[-D_Selected:]\n",
    "XFiltered_train_selected = XFiltered_train[:, top_features_indices]\n",
    "XFiltered_test_selected = XFiltered_test[:, top_features_indices]\n",
    "featureFrequenciesFiltered_Selected = featureFrequenciesFiltered[top_features_indices]\n",
    "wordsFiltered_selected = [wordsFiltered[i] for i in top_features_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Displaying Top Words (Task 3.1)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with the 10 largest positive weights:\n",
      "Word: 'recommended', Weight: 1.53338, Frequency: 484\n",
      "Word: 'funniest', Weight: 1.27472, Frequency: 330\n",
      "Word: 'superb', Weight: 1.24865, Frequency: 621\n",
      "Word: 'wonderfully', Weight: 1.21076, Frequency: 311\n",
      "Word: 'available', Weight: 1.03583, Frequency: 364\n",
      "Word: 'excellent', Weight: 1.01886, Frequency: 1778\n",
      "Word: 'loved', Weight: 0.98732, Frequency: 1232\n",
      "Word: 'tears', Weight: 0.97909, Frequency: 303\n",
      "Word: 'fascinating', Weight: 0.95847, Frequency: 362\n",
      "Word: 'enjoyed', Weight: 0.94308, Frequency: 1141\n",
      "\n",
      "\n",
      "Words with the 10 largest negative weights:\n",
      "Word: 'numerous', Weight: -0.92684, Frequency: 256\n",
      "Word: 'honestly', Weight: -0.83400, Frequency: 423\n",
      "Word: 'plus', Weight: -0.59289, Frequency: 562\n",
      "Word: 'allow', Weight: -0.57192, Frequency: 296\n",
      "Word: 'review', Weight: -0.56384, Frequency: 751\n",
      "Word: 'amount', Weight: -0.56081, Frequency: 463\n",
      "Word: 'worst', Weight: -0.53833, Frequency: 2261\n",
      "Word: 'prove', Weight: -0.52345, Frequency: 252\n",
      "Word: 'seemingly', Weight: -0.51926, Frequency: 326\n",
      "Word: 'included', Weight: -0.50593, Frequency: 262\n"
     ]
    }
   ],
   "source": [
    "numberOfWordsToDisplay = 10 #both positive and negative side\n",
    "positive_weights_indices = np.argsort(weights)[-numberOfWordsToDisplay:]\n",
    "negative_weights_indices = np.argsort(weights)[:numberOfWordsToDisplay]\n",
    "words_with_largest_positive_weights = [(wordsFiltered[i].strip(), weights[i], featureFrequenciesFiltered[i]) for i in positive_weights_indices]\n",
    "words_with_largest_negative_weights = [(wordsFiltered[i].strip(), weights[i], featureFrequenciesFiltered[i]) for i in negative_weights_indices]\n",
    "\n",
    "print(f\"Words with the {numberOfWordsToDisplay} largest positive weights:\")\n",
    "for word, weight, frequency in reversed(words_with_largest_positive_weights):\n",
    "    print(f\"Word: '{word}', Weight: {weight:.5f}, Frequency: {frequency}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Words with the {numberOfWordsToDisplay} largest negative weights:\")\n",
    "for word, weight, frequency in words_with_largest_negative_weights:\n",
    "    print(f\"Word: '{word}', Weight: {weight:.5f}, Frequency: {frequency}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GrITPythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
